{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEP532 인공지능 이론과 실제\n",
    "## Deep Learning Practice \n",
    "#### Prof. Ho-Jin Choi\n",
    "#### School of Computing, KAIST\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Advanced Models\n",
    "### Sequence to Sequence (seq2seq)\n",
    "\n",
    "Today we will learn a new neural network architecture, so-called sequence-to-sequence (seq2seq), for language processing (e.g. language translation, image captioning, conversational models and text summarization).\n",
    "\n",
    "This is made possible by the simple but powerful idea of the sequence to sequence network, in which two recurrent neural networks work together to transform one sequence to another. An encoder network condenses an input sequence into a single vector, and a decoder network unfolds that vector into a new sequence.\n",
    "\n",
    "![Sequence to sequence model](images/seq2seq.png)\n",
    "\n",
    "#### Encoder\n",
    "- A stack of several recurrent units (LSTM or GRU cells for better performance) where each accepts a single element of the input sequence, collects information for that element and propagates it forward.\n",
    "- In question-answering problem, the input sequence is a collection of all words from the question. Each word is represented as $x_i$ where $i$ is the order of that word.\n",
    "\n",
    "#### Context Vector\n",
    "- This is the final hidden state produced from the encoder part of the model. It is calculated using the formula above.\n",
    "- This vector aims to encapsulate the information for all input elements in order to help the decoder make accurate predictions.\n",
    "- It acts as the initial hidden state of the decoder part of the model.\n",
    "\n",
    "#### Decoder\n",
    "- A stack of several recurrent units where each predicts an output $y_t$ at a time step $t$.\n",
    "- Each recurrent unit accepts a hidden state from the previous unit and produces and output as well as its own hidden state.\n",
    "- In the question-answering problem, the output sequence is a collection of all words from the answer. Each word is represented as $y_i$ where $i$ is the order of that word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preprocess the dataset\n",
    "\n",
    "We'll use a Korean chatbot dataset provided by https://github.com/songys/Chatbot_data. This dataset contains almost 12,000 question and answer pairs and served as the csv format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --output-document=\"chatbot.csv\" https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset consists of three columns:\n",
    "- `Q`: question sentence\n",
    "- `A`: answer sentence\n",
    "- `label`: sentiment lab\n",
    "\n",
    "Among these columns, we are going to use only `Q` and `A`. Let's load this dataset using `pandas.read_csv()`. For readability purposes, we are going to rename columns from `Q` and `A` to `question` and `answer` respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the dataset is loaded. Let's vectorize this dataset to feed this dataset into a neural network. To do that, we need to build a tokenizer to split a sentence into several tokens and to give indexes to each token. \n",
    "\n",
    "For Korean language, there are several methods to build tokenizers but, in this notebook, we will use the following two methods:\n",
    "- A subword tokenizer\n",
    "- A tokenizer based on part-of-speech tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the subword tokenizer\n",
    "![Subword](images/subword.png)\n",
    "\n",
    "Let's build the subword tokenizer to tokenize the given texts as several subwords and to transform the subword tokens into integer vectors. To do that, we are going to use `SubwordTextEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.concat([df['question'], df['answer']], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "SubwordTextEncoder = tfds.deprecated.text.SubwordTextEncoder\n",
    "\n",
    "tokenizer = SubwordTextEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_token = \n",
    "end_token = \n",
    "\n",
    "def encode(text):\n",
    "    pass\n",
    "\n",
    "def decode(tokens):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_words = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the tokenizer based on part-of-speech tagger\n",
    "![Part-of-speech](images/part-of-speech.png)\n",
    "\n",
    "Let's build the tokenizer based on part-of-speech tagger to tokenize the given texts as several morphemes and to transform the morpheme tokens into integer vectors. To do that, we are going to use `konlpy` library which provides several part-of-speech taggers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "def preprocess_sentence(text):\n",
    "    pass\n",
    "\n",
    "corpus = \n",
    "corpus = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = \n",
    "tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_token = \n",
    "end_token = \n",
    "\n",
    "def encode(text):\n",
    "    pass\n",
    "\n",
    "def decode(tokens):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_words = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After building tokenizers, `encode()` and `decode()`, let's vectorize the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = \n",
    "questions = \n",
    "\n",
    "answers = \n",
    "answers = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `tf.data.Dataset`'s methods, shuffle the dataset and make its batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "number_of_dataset = questions.shape[0]\n",
    "\n",
    "dataset = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define seq2seq model\n",
    "\n",
    "Now, it is time to build the encoder and decoder models. Because these models are not provided by TensorFlow and Keras by default, we need to define our `tf.keras.Model` by manual using the class inheritance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Encoder` model takes an input vector and produces a context vector which summarizes all the input vector. To do that, we need the following layers:\n",
    "\n",
    "- `tf.keras.layers.Embedding`\n",
    "- `tf.keras.layers.GRU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, units):\n",
    "        super().__init__()\n",
    "        \n",
    "    def call(self, encoder_input, encoder_state):\n",
    "        # encoder_input = (batch_size, length)\n",
    "        # encoder_state = (batch_size, units)\n",
    "\n",
    "        # encoder_input = (batch_size, length, embedding_dim)\n",
    "        encoder_input = \n",
    "        \n",
    "        # encoder_output = (batch_size, units)\n",
    "        # encoder_state = (batch_size, units)\n",
    "        encoder_output, encoder_state = \n",
    "        \n",
    "        return encoder_output, encoder_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Decoder` model takes the context vector from the `Encoder` and predicts a next word given the previous word inputs. In other words, `Decoder` model calculates this conditional probability: $ P(\\text{word}_{t + 1}|\\text{context}, \\text{word}_1, \\text{word}_2, \\dots, \\text{word}_t) $\n",
    "\n",
    "To do that, we need the following layers:\n",
    "\n",
    "- `tf.keras.layers.Embedding`\n",
    "- `tf.keras.layers.GRU`\n",
    "- `tf.keras.layers.Dense`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, units):\n",
    "        super().__init__()\n",
    "        \n",
    "    def call(self, decoder_input, decoder_state):\n",
    "        # decoder_input = (batch_size, 1)\n",
    "        # decoder_state = (batch_size, units)\n",
    "\n",
    "        # decoder_input = (batch_size, 1, embedding_dim)\n",
    "        decoder_input = \n",
    "\n",
    "        # decoder_output = (batch_size, units)\n",
    "        # decoder_state = (batch_size, units)\n",
    "        decoder_output, decoder_state = \n",
    "        \n",
    "        # decoder_output = (batch_size, vocab_size)\n",
    "        decoder_output = \n",
    "        \n",
    "        return decoder_output, decoder_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once both the encoder and decoder are defined, we can initiate them like normal Python classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 256\n",
    "units = 1024\n",
    "\n",
    "encoder = \n",
    "decoder = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the loss and optimizer\n",
    "\n",
    "Let's define the loss functions and the optimizers for the seq2seq model. Here, because the input dataset consists sentences of various lengths, we need to consider that point when caclculating the loss. Otherwise, the loss will be too grater than expected. To do that, we create a `mask` matrix and discard unnecessary values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "def calculate_loss(actual, predicted):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train seq2seq model using `tf.GradientTape`\n",
    "\n",
    "In this notebook, rather than using `tf.keras.Model.fit()`, we will train the model more manaully using `tf.GradientTape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(encoder_input, decoder_target):\n",
    "    loss = 0\n",
    "    with tf.GradientTape() as tape:\n",
    "        pass\n",
    "    \n",
    "    batch_loss = loss / int(decoder_target.shape[1])\n",
    "    \n",
    "    variables = \n",
    "    gradients = \n",
    "    optimizer.\n",
    "    \n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "epoch_loss = tf.keras.metrics.Mean()\n",
    "with tqdm(total=epochs) as epoch_progress:\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss.reset_states()\n",
    "\n",
    "        with tqdm(total=number_of_dataset // batch_size) as batch_progress:\n",
    "            for batch, (encoder_input, decoder_target) in enumerate(dataset):\n",
    "                batch_loss = train_step(encoder_input, decoder_target)\n",
    "                epoch_loss(batch_loss)\n",
    "                \n",
    "                if (batch % 10) == 0:\n",
    "                    batch_progress.set_description(f'Epoch {epoch + 1}')\n",
    "                    batch_progress.set_postfix(Batch=batch, Loss=batch_loss.numpy())\n",
    "                batch_progress.update()\n",
    "        \n",
    "        epoch_progress.set_description(f'Epoch {epoch + 1}')\n",
    "        epoch_progress.set_postfix(Loss=epoch_loss.result().numpy())\n",
    "        epoch_progress.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's generate a response for a given sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listen(sentence):\n",
    "    encoder_input = \n",
    "    encoder_input = \n",
    "\n",
    "    encoder_state = \n",
    "    encoder_output, encoder_state = \n",
    "\n",
    "    decoder_state = encoder_state\n",
    "    decoder_input = \n",
    "\n",
    "    predicted = []\n",
    "    for step in range(answers.shape[1]):\n",
    "        predictions, decoder_state = \n",
    "\n",
    "        predicted_id = \n",
    "        if predicted_id == end_token:\n",
    "            break\n",
    "\n",
    "        predicted.append(predicted_id)\n",
    "        decoder_input = \n",
    "\n",
    "    return decode(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listen('반갑습니다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listen('오늘 날씨가 좋네요')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
