{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEP532 인공지능 이론과 실제\n",
    "## Deep Learning Practice \n",
    "#### Prof. Ho-Jin Choi\n",
    "#### School of Computing, KAIST\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks\n",
    "### Introduction to RNNs\n",
    "#### Why the RNNs?\n",
    "Traditional neural networks such as FFNN, CNN have no **persistence properties** when predicting some results (e.g., as you read this sentence, you understand each word based on your understanding of previous words). This is a major shortcoming of the neural networks. \n",
    "\n",
    "![Recurrent Neural Network](images/rnn.png)\n",
    "\n",
    "Recurrent neural networks address this issue. They are networks with loops in them, allowing information to persist. RNN is a class of artificial neural network where connections between units form a directed graph along a temporal sequence. This allows it to exhibit temporal dynamic behavior. Unlike feedforward neural networks, RNNs can use their internal state (memory) to process sequences of inputs. This makes them applicable to tasks such as sentence generation, machine translation, image captioning or speech recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanishing Gradient Problem\n",
    "Vanishing gradient problem is a difficulty found in training artificial neural networks with gradient-based learning methods and backpropagation. In such methods, each of the neural network's weights receives an update proportional to the partial derivative of the error function with respect to the current weight in each iteration of training. \n",
    "\n",
    "The problem is that in some cases, **the gradient will be vanishingly small**, effectively preventing the weight from changing its value. **In the worst case**, this **may completely stop the neural network from further training**. \n",
    "\n",
    "![tanh and its derivative](images/tanh-and-tanh-derivative.png)\n",
    "As one example of the problem cause, traditional activation functions such as the hyperbolic tangent function have gradients in the range `(0, 1)`, and backpropagation computes gradients by the chain rule. This has the effect of **multiplying $n$ of these small numbers to compute gradients of the \"front\" layers in an $n$-layer network**, meaning that the gradient (error signal) decreases exponentially with $n$ while the front layers train very slowly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example of vanishing gradient\n",
    "- Sentence 1: That **_cat_**, which already ate ..., **_was_** full.\n",
    "- Sentence 2: That **_cats_**, which already ate ..., **_were_** full.\n",
    "\n",
    "This is one example when language can have long term dependencies. Like in above example **_cat_** which came early in the sentence can affect what came later.\n",
    "\n",
    "![Example of vanishing gradient](images/example-of-vanishing-gradient.png)\n",
    "\n",
    "However, the basic recurrent neural network is not very good in remembering long term dependencies. The output in this network can mostly be affected by the value close to it. Thus, $\\hat{y}^{<3>}$ is mainly influenced by values close to $\\hat{y}^{<3>}$ ($x^{<1>}$, $x^{<2>}$, $x^{<3>}$).\n",
    "\n",
    "In other words, in the case of $\\hat{y}^{<T_y>}$, this cannot be influenced by the early inputs in the sequences ($x^{<1>}$, $x^{<2>}$, $x^{<3>}$) because it is hard for the error to be backpropagated to the beginning of the sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Long short-term memory (LSTM)\n",
    "\n",
    "![Long short-term memory](images/lstm.png)\n",
    "\n",
    "Long Short-Term Memory networks – usually just called \"LSTMs\" – are a special kind of RNN, capable of learning long-term dependencies. They work tremendously well on a large variety of problems, and are now widely used. LSTMs are explicitly designed to avoid the long-term dependency problem. Remembering information for long periods of time is practically their default behavior.\n",
    "\n",
    "A common LSTM unit is composed of a **cell**, an **input gate**, an **output gate** and a **forget gate**. The cell is responsible for _\"remembering\" values over arbitrary time intervals_; hence the word \"memory\" in LSTM. Each of the three gates can be thought intuitively as regulators of the flow of values that goes through the connections of the LSTM.\n",
    "\n",
    "\n",
    "For more detailed LSTM:\n",
    "https://colah.github.io/posts/2015-08-Understanding-LSTMs/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
