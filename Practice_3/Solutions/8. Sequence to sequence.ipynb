{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SEP532 인공지능 이론과 실제\n",
    "## Deep Learning Practice \n",
    "#### Prof. Ho-Jin Choi\n",
    "#### School of Computing, KAIST\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Models\n",
    "### Sequence to Sequence (seq2seq)\n",
    "\n",
    "Today we will learn a new neural network architecture, so-called sequence-to-sequence (seq2seq), for language processing (e.g. language translation, image captioning, conversational models and text summarization).\n",
    "\n",
    "This is made possible by the simple but powerful idea of the sequence to sequence network, in which two recurrent neural networks work together to transform one sequence to another. An encoder network condenses an input sequence into a single vector, and a decoder network unfolds that vector into a new sequence.\n",
    "\n",
    "![Sequence to sequence model](images/seq2seq.png)\n",
    "\n",
    "#### Encoder\n",
    "- A stack of several recurrent units (LSTM or GRU cells for better performance) where each accepts a single element of the input sequence, collects information for that element and propagates it forward.\n",
    "- In question-answering problem, the input sequence is a collection of all words from the question. Each word is represented as $x_i$ where $i$ is the order of that word.\n",
    "\n",
    "#### Context Vector\n",
    "- This is the final hidden state produced from the encoder part of the model. It is calculated using the formula above.\n",
    "- This vector aims to encapsulate the information for all input elements in order to help the decoder make accurate predictions.\n",
    "- It acts as the initial hidden state of the decoder part of the model.\n",
    "\n",
    "#### Decoder\n",
    "- A stack of several recurrent units where each predicts an output $y_t$ at a time step $t$.\n",
    "- Each recurrent unit accepts a hidden state from the previous unit and produces and output as well as its own hidden state.\n",
    "- In the question-answering problem, the output sequence is a collection of all words from the answer. Each word is represented as $y_i$ where $i$ is the order of that word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preprocess the dataset\n",
    "\n",
    "We'll use a Korean chatbot dataset provided by https://github.com/songys/Chatbot_data. This dataset contains almost 12,000 question and answer pairs and served as the csv format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-05-09 01:41:20--  https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 889842 (869K) [text/plain]\n",
      "Saving to: ‘chatbot.csv’\n",
      "\n",
      "chatbot.csv         100%[===================>] 868.99K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2022-05-09 01:41:20 (36.7 MB/s) - ‘chatbot.csv’ saved [889842/889842]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --output-document=\"chatbot.csv\" https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset consists of three columns:\n",
    "- `Q`: question sentence\n",
    "- `A`: answer sentence\n",
    "- `label`: sentiment lab\n",
    "\n",
    "Among these columns, we are going to use only `Q` and `A`. Let's load this dataset using `pandas.read_csv()`. For readability purposes, we are going to rename columns from `Q` and `A` to `question` and `answer` respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SD카드 망가졌어</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SD카드 안돼</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SNS 맞팔 왜 안하지ㅠㅠ</td>\n",
       "      <td>잘 모르고 있을 수도 있어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SNS 시간낭비인 거 아는데 매일 하는 중</td>\n",
       "      <td>시간을 정하고 해보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SNS 시간낭비인데 자꾸 보게됨</td>\n",
       "      <td>시간을 정하고 해보세요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  question              answer\n",
       "0                   12시 땡!          하루가 또 가네요.\n",
       "1              1지망 학교 떨어졌어           위로해 드립니다.\n",
       "2             3박4일 놀러가고 싶다         여행은 언제나 좋죠.\n",
       "3          3박4일 정도 놀러가고 싶다         여행은 언제나 좋죠.\n",
       "4                  PPL 심하네          눈살이 찌푸려지죠.\n",
       "5                SD카드 망가졌어  다시 새로 사는 게 마음 편해요.\n",
       "6                  SD카드 안돼  다시 새로 사는 게 마음 편해요.\n",
       "7           SNS 맞팔 왜 안하지ㅠㅠ    잘 모르고 있을 수도 있어요.\n",
       "8  SNS 시간낭비인 거 아는데 매일 하는 중       시간을 정하고 해보세요.\n",
       "9        SNS 시간낭비인데 자꾸 보게됨       시간을 정하고 해보세요."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('chatbot.csv', usecols=['Q', 'A']).rename(columns={'Q': 'question', 'A': 'answer'})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the dataset is loaded. Let's vectorize this dataset to feed this dataset into a neural network. To do that, we need to build a tokenizer to split a sentence into several tokens and to give indexes to each token. \n",
    "\n",
    "For Korean language, there are several methods to build tokenizers but, in this notebook, we will use the following two methods:\n",
    "- A subword tokenizer\n",
    "- A tokenizer based on part-of-speech tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the subword tokenizer\n",
    "![Subword](images/subword.png)\n",
    "\n",
    "Let's build the subword tokenizer to tokenize the given texts as several subwords and to transform the subword tokens into integer vectors. To do that, we are going to use `tensorflow_datasets.features.SubwordTextEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.concat([df['question'], df['answer']], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "SubwordTextEncoder = tfds.deprecated.text.SubwordTextEncoder\n",
    "\n",
    "tokenizer = SubwordTextEncoder.build_from_corpus(corpus, target_vocab_size=2 ** 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SubwordTextEncoder' object has no attribute 'vocab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SubwordTextEncoder' object has no attribute 'vocab'"
     ]
    }
   ],
   "source": [
    "tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_token = tokenizer.vocab_size\n",
    "end_token = tokenizer.vocab_size + 1\n",
    "\n",
    "def encode(text):\n",
    "    return [start_token] + tokenizer.encode(text) + [end_token]\n",
    "\n",
    "def decode(tokens):\n",
    "    return tokenizer.decode(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_words = tokenizer.vocab_size + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the tokenizer based on part-of-speech tagger\n",
    "![Part-of-speech](images/part-of-speech.png)\n",
    "\n",
    "Let's build the tokenizer based on part-of-speech tagger to tokenize the given texts as several morphemes and to transform the morpheme tokens into integer vectors. To do that, we are going to use `konlpy` library which provides several part-of-speech taggers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting konlpy\n",
      "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting lxml>=4.1.0\n",
      "  Downloading lxml-4.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting JPype1>=0.7.0\n",
      "  Downloading JPype1-1.3.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (449 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.3/449.3 KB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.9/site-packages (from konlpy) (1.22.3)\n",
      "Installing collected packages: JPype1, lxml, konlpy\n",
      "Successfully installed JPype1-1.3.0 konlpy-0.6.0 lxml-4.8.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "def preprocess_sentence(text):\n",
    "    return '<start> {} <end>'.format(' '.join(okt.morphs(text)))\n",
    "\n",
    "corpus = pd.concat([df['question'], df['answer']], ignore_index=True)\n",
    "corpus = corpus.apply(preprocess_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "tokenizer.fit_on_texts(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_token = tokenizer.word_index['<start>']\n",
    "end_token = tokenizer.word_index['<end>']\n",
    "\n",
    "def encode(text):\n",
    "    return [start_token] + tokenizer.texts_to_sequences([' '.join(okt.morphs(text))])[0] + [end_token]\n",
    "\n",
    "def decode(tokens):\n",
    "    return tokenizer.sequences_to_texts([tokens])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_words = len(tokenizer.word_index) + 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After building tokenizers, `encode()` and `decode()`, let's vectorize the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [encode(question) for question in df['question']]\n",
    "questions = tf.keras.preprocessing.sequence.pad_sequences(questions, padding='post')\n",
    "\n",
    "answers = [encode(answer) for answer in df['answer']]\n",
    "answers = tf.keras.preprocessing.sequence.pad_sequences(answers, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `tf.data.Dataset`'s methods, shuffle the dataset and make its batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 00:05:36.633082: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-09 00:05:37.362972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 34845 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:18:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "number_of_dataset = questions.shape[0]\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((questions, answers)).shuffle(number_of_dataset).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define seq2seq model\n",
    "\n",
    "Now, it is time to build the encoder and decoder models. Because these models are not provided by TensorFlow and Keras by default, we need to define our `tf.keras.Model` by manual using the class inheritance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Encoder` model takes an input vector and produces a context vector which summarizes all the input vector. To do that, we need the following layers:\n",
    "\n",
    "- `tf.keras.layers.Embedding`\n",
    "- `tf.keras.layers.GRU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, units):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.units, return_state=True)\n",
    "        \n",
    "    def call(self, encoder_input, encoder_state):\n",
    "        # encoder_input = (batch_size, length)\n",
    "        # encoder_state = (batch_size, units)\n",
    "\n",
    "        # encoder_input = (batch_size, length, embedding_dim)\n",
    "        encoder_input = self.embedding(encoder_input)\n",
    "        \n",
    "        # encoder_output = (batch_size, units)\n",
    "        # encoder_state = (batch_size, units)\n",
    "        encoder_output, encoder_state = self.gru(encoder_input, initial_state=encoder_state)\n",
    "        \n",
    "        return encoder_output, encoder_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Decoder` model takes the context vector from the `Encoder` and predicts a next word given the previous word inputs. In other words, `Decoder` model calculates this conditional probability: $ P(\\text{word}_{t + 1}|\\text{context}, \\text{word}_1, \\text{word}_2, \\dots, \\text{word}_t) $\n",
    "\n",
    "To do that, we need the following layers:\n",
    "\n",
    "- `tf.keras.layers.Embedding`\n",
    "- `tf.keras.layers.GRU`\n",
    "- `tf.keras.layers.Dense`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, units):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.units, return_state=True)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, decoder_input, decoder_state):\n",
    "        # decoder_input = (batch_size, 1)\n",
    "        # decoder_state = (batch_size, units)\n",
    "\n",
    "        # decoder_input = (batch_size, 1, embedding_dim)\n",
    "        decoder_input = self.embedding(decoder_input)\n",
    "\n",
    "        # decoder_output = (batch_size, units)\n",
    "        # decoder_state = (batch_size, units)\n",
    "        decoder_output, decoder_state = self.gru(decoder_input, initial_state=decoder_state)\n",
    "        \n",
    "        # decoder_output = (batch_size, vocab_size)\n",
    "        decoder_output = self.fc(decoder_output)\n",
    "        \n",
    "        return decoder_output, decoder_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once both the encoder and decoder are defined, we can initiate them like normal Python classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 256\n",
    "units = 1024\n",
    "\n",
    "encoder = Encoder(number_of_words, embedding_dim, units)\n",
    "decoder = Decoder(number_of_words, embedding_dim, units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the loss and optimizer\n",
    "\n",
    "Let's define the loss functions and the optimizers for the seq2seq model. Here, because the input dataset consists sentences of various lengths, we need to consider that point when caclculating the loss. Otherwise, the loss will be too grater than expected. To do that, we create a `mask` matrix and discard unnecessary values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "def calculate_loss(actual, predicted):\n",
    "    mask = tf.math.logical_not(tf.math.equal(actual, 0))\n",
    "    loss = _loss(actual, predicted)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "    \n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train seq2seq model using `tf.GradientTape`\n",
    "\n",
    "In this notebook, rather than using `tf.keras.Model.fit()`, we will train the model more manaully using `tf.GradientTape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(encoder_input, decoder_target):\n",
    "    loss = 0\n",
    "    with tf.GradientTape() as tape:\n",
    "        encoder_state = tf.zeros((batch_size, encoder.units))\n",
    "        encoder_output, encoder_state = encoder(encoder_input, encoder_state)\n",
    "        \n",
    "        decoder_state = encoder_state\n",
    "        decoder_input = tf.expand_dims([start_token] * batch_size, 1)\n",
    "        \n",
    "        for step in range(1, decoder_target.shape[1]):\n",
    "            predictions, decoder_state = decoder(decoder_input, decoder_state)\n",
    "            loss += calculate_loss(decoder_target[:, step], predictions)\n",
    "            \n",
    "            decoder_input = tf.expand_dims(decoder_target[:, step], 1)\n",
    "            \n",
    "    batch_loss = loss / int(decoder_target.shape[1])\n",
    "    \n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622b0d072e9843c7b510874f699aa1b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c141c62c9644546867c45c0fdff6d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 00:05:40.022736: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101\n",
      "2022-05-09 00:05:41.424124: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0515cc1e3c645a28a6a63316980e7bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60fcd0dd7a07422f9e4203f1ae5759db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2710d6ae9cd84f8fb835d041d0284a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3b2ed9ccdec46a5bc9f6bef2c732d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac79a277642423b9b6d0d97228d7423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef3308b031ac4b079f52b8225e73627a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70f8f8ed0f749449cd0871948418f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d40e93ccef4143a6aa3419e498c2193e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a5971c15294095985bd222dfe843f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "epoch_loss = tf.keras.metrics.Mean()\n",
    "with tqdm(total=epochs) as epoch_progress:\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss.reset_states()\n",
    "\n",
    "        with tqdm(total=number_of_dataset // batch_size) as batch_progress:\n",
    "            for batch, (encoder_input, decoder_target) in enumerate(dataset):\n",
    "                batch_loss = train_step(encoder_input, decoder_target)\n",
    "                epoch_loss(batch_loss)\n",
    "                \n",
    "                if (batch % 10) == 0:\n",
    "                    batch_progress.set_description(f'Epoch {epoch + 1}')\n",
    "                    batch_progress.set_postfix(Batch=batch, Loss=batch_loss.numpy())\n",
    "                batch_progress.update()\n",
    "        \n",
    "        epoch_progress.set_description(f'Epoch {epoch + 1}')\n",
    "        epoch_progress.set_postfix(Loss=epoch_loss.result().numpy())\n",
    "        epoch_progress.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's generate a response for a given sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def listen(sentence):\n",
    "    encoder_input = encode(sentence)\n",
    "    encoder_input = tf.keras.preprocessing.sequence.pad_sequences([encoder_input], maxlen=questions.shape[1], padding='post')\n",
    "\n",
    "    encoder_state = tf.zeros((1, encoder.units))\n",
    "    encoder_output, encoder_state = encoder(encoder_input, encoder_state)\n",
    "\n",
    "    decoder_state = encoder_state\n",
    "    decoder_input = tf.expand_dims([start_token], 0)\n",
    "\n",
    "    predicted = []\n",
    "    for step in range(answers.shape[1]):\n",
    "        predictions, decoder_state = decoder(decoder_input, decoder_state)\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        if predicted_id == end_token:\n",
    "            break\n",
    "\n",
    "        predicted.append(predicted_id)\n",
    "        decoder_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return decode(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'사랑 은 따지는 게 아니고 다 주 고도 더 주지 못 해 미안해하는 거 예요 .'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listen('반갑습니다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'좋은 만남이었길 바라요 .'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listen('오늘 날씨가 좋네요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 00:09:54.894764: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: sequence-to-sequence/encoder/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: sequence-to-sequence/encoder/assets\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f027ac28bb0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:Found untraced functions such as gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: sequence-to-sequence/decoder/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: sequence-to-sequence/decoder/assets\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f027aaaf7f0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "!mkdir sequence-to-sequence/encoder\n",
    "!mkdir sequence-to-sequence/decoder\n",
    "encoder.save('sequence-to-sequence/encoder')\n",
    "decoder.save('sequence-to-sequence/decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
