{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEP532 Ïù∏Í≥µÏßÄÎä• Ïù¥Î°†Í≥º Ïã§Ï†ú\n",
    "## Deep Learning Practice \n",
    "#### Prof. Ho-Jin Choi\n",
    "#### School of Computing, KAIST\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kagggle: Real or Not? NLP with Disaster Tweets\n",
    "In this practice, we are going to build a machine learning model that predicts which Tweets are about real disasters and which one‚Äôs aren‚Äôt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Kaggle - Real or Not? NLP with Disaster Tweets](https://www.kaggle.com/c/nlp-getting-started)\n",
    "\n",
    "> Twitter has become an important communication channel in times of emergency.\n",
    "> The ubiquitousness of smartphones enables people to announce an emergency they‚Äôre observing in real-time. \n",
    "> Because of this, more agencies are interested in programatically monitoring Twitter (i.e. disaster relief organizations and news agencies).\n",
    ">\n",
    "> But, it‚Äôs not always clear whether a person‚Äôs words are actually announcing a disaster. Take this example:\n",
    "> ![On plus side LOOK AT THE SKY LAST NIGHT IT WAS ABLAZE](images/example-tweet.png)\n",
    ">\n",
    "> The author explicitly uses the word ‚ÄúABLAZE‚Äù but means it metaphorically. This is clear to a human right away, especially with the visual aid.\n",
    "> But it‚Äôs less clear to a machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preprocess dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are going to use `Pandas` to load and process the dataset. Let's load the dataset given in `.csv` format using `pandas.read_csv()`.\n",
    "\n",
    "The given dataset consists of 5 columns:\n",
    "- `id`\n",
    "- `keyword`\n",
    "- `location`\n",
    "- `text`\n",
    "- `target`\n",
    "\n",
    "Among these columns, we are going to use only `text` and `target` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#flood #disaster Heavy rain causes flash flood...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>There's an emergency evacuation happening now ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1             Forest fire near La Ronge Sask. Canada       1\n",
       "2  All residents asked to 'shelter in place' are ...       1\n",
       "3  13,000 people receive #wildfires evacuation or...       1\n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1\n",
       "5  #RockyFire Update => California Hwy. 20 closed...       1\n",
       "6  #flood #disaster Heavy rain causes flash flood...       1\n",
       "7  I'm on top of the hill and I can see a fire in...       1\n",
       "8  There's an emergency evacuation happening now ...       1\n",
       "9  I'm afraid that the tornado is coming to our a...       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('disaster-tweets.csv', usecols=['text', 'target'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define `clean_text()` function to clean texts in the dataset. For example, this function\n",
    "- Converts all uppercase characters in a text into lowercase characters\n",
    "- Remove accents\n",
    "- Removes URLs in a text\n",
    "- Removes all punctuations in a text\n",
    "- Removes all characters other than alphabet, digit and whitespace\n",
    "- Merges consecutive whitespaces into one whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import unicodedata \n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join(character for character in unicodedata.normalize('NFD', text) if unicodedata.category(character) != 'Mn')\n",
    "    \n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(fr'[{re.escape(string.punctuation)}]', '', text)\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, apply `clean_text()` to `df['text']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13000 people receive wildfires evacuation orde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rockyfire update california hwy 20 closed in b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>flood disaster heavy rain causes flash floodin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>im on top of the hill and i can see a fire in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>theres an emergency evacuation happening now i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>im afraid that the tornado is coming to our area</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  our deeds are the reason of this earthquake ma...       1\n",
       "1              forest fire near la ronge sask canada       1\n",
       "2  all residents asked to shelter in place are be...       1\n",
       "3  13000 people receive wildfires evacuation orde...       1\n",
       "4  just got sent this photo from ruby alaska as s...       1\n",
       "5  rockyfire update california hwy 20 closed in b...       1\n",
       "6  flood disaster heavy rain causes flash floodin...       1\n",
       "7  im on top of the hill and i can see a fire in ...       1\n",
       "8  theres an emergency evacuation happening now i...       1\n",
       "9   im afraid that the tornado is coming to our area       1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].apply(clean_text)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define `train_test_split()` which splits a given `DataFrame` into train and test subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, ratio=0.8):\n",
    "    number_of_rows = df.shape[0]\n",
    "    positions = np.arange(number_of_rows)\n",
    "    np.random.shuffle(positions)\n",
    "    \n",
    "    pivot = int(number_of_rows * ratio)\n",
    "    train_positions = positions[:pivot]\n",
    "    test_positions = positions[pivot:]\n",
    "    \n",
    "    return df.iloc[train_positions], df.iloc[test_positions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can split the dataset into train, validation, and test `DataFrame`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_validtion, df_test = train_test_split(df, ratio=0.8)\n",
    "df_train, df_validation = train_test_split(df_train_validtion, ratio=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define `prepare_tensors()` to convert the `DataFrame` into `X` and `y` tensors. Use `tf.keras.preprocessing.text.Tokenizer` to tokenize texts into sequences of words and convert them into numerical tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<unk>')\n",
    "tokenizer.fit_on_texts(df_train['text'])\n",
    "\n",
    "def prepare_tensors(df):\n",
    "    sequences = tokenizer.texts_to_sequences(df['text'])\n",
    "    \n",
    "    X = tf.keras.preprocessing.sequence.pad_sequences(sequences, padding='post')\n",
    "    y = df['target'].to_numpy()\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = prepare_tensors(df_train)\n",
    "X_validation, y_validation = prepare_tensors(df_validation)\n",
    "X_test, y_test = prepare_tensors(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the model\n",
    "\n",
    "Build the model using `tf.keras.Sequuential` and other `tf.keras.layers.*` layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64, mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, dropout=0.3)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the model\n",
    "Compile the model using `binary_crossentropy` loss and optimizers as choice. Also, we can monitor the performance of the network using `accuracy` as metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model\n",
    "Train the model using `tf.keras.Model.fit()`. Use `tf.keras.callbacks.EarlyStopping` to stop the training when the validation loss increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 7s 93ms/step - loss: 0.6854 - accuracy: 0.5616 - val_loss: 0.6271 - val_accuracy: 0.6470\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.5554 - accuracy: 0.7387 - val_loss: 0.5292 - val_accuracy: 0.7660\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.3078 - accuracy: 0.8898 - val_loss: 0.5198 - val_accuracy: 0.7865\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1590 - accuracy: 0.9491 - val_loss: 0.6143 - val_accuracy: 0.7931\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0996 - accuracy: 0.9717 - val_loss: 0.7046 - val_accuracy: 0.7923\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0654 - accuracy: 0.9796 - val_loss: 0.7617 - val_accuracy: 0.7791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f440490f340>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=10, \n",
    "    batch_size=256,\n",
    "    validation_data=(X_validation, y_validation), \n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5554, Accuracy: 0.7800\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: the latest more homes razed by northern california wildfire\n",
      "Preprocessed: the latest more homes razed by northern california wildfire\n",
      "Actual: üåãDisaster\n",
      "Predicted: üåãDisaster\n",
      "\n",
      "Input: wwe 2k15 mycareer ep18 tyrone body bagging dudes via youtube\n",
      "Preprocessed: wwe 2k15 <unk> <unk> <unk> body bagging dudes via youtube\n",
      "Actual: üåçNon-disaster\n",
      "Predicted: üåçNon-disaster\n",
      "\n",
      "Input: the drought is real\n",
      "Preprocessed: the drought is real\n",
      "Actual: üåãDisaster\n",
      "Predicted: üåçNon-disaster\n",
      "\n",
      "Input: the second part which focuses on the survivors is really difficult to watch but at the same time is really powerful\n",
      "Preprocessed: the second part which <unk> on the survivors is really <unk> to watch but at the same time is really powerful\n",
      "Actual: üåãDisaster\n",
      "Predicted: üåãDisaster\n",
      "\n",
      "Input: thus making femalegilgameshs assault useless the spears collided with the dark force however did not penetrate due to the dark\n",
      "Preprocessed: thus making <unk> <unk> <unk> the spears collided with the dark force however did not <unk> due to the dark\n",
      "Actual: üåçNon-disaster\n",
      "Predicted: üåãDisaster\n",
      "\n",
      "Input: gotta love summer in calgary yyc hailstorm crazyweather\n",
      "Preprocessed: gotta love summer in calgary yyc hailstorm <unk>\n",
      "Actual: üåãDisaster\n",
      "Predicted: üåãDisaster\n",
      "\n",
      "Input: screams\n",
      "Preprocessed: screams\n",
      "Actual: üåçNon-disaster\n",
      "Predicted: üåçNon-disaster\n",
      "\n",
      "Input: obama declares disaster for typhoondevastated saipan obama signs disaster declaration for northern marians a\n",
      "Preprocessed: obama declares disaster for typhoondevastated saipan obama signs disaster declaration for northern marians a\n",
      "Actual: üåãDisaster\n",
      "Predicted: üåãDisaster\n",
      "\n",
      "Input: viennabutcher its not funny im traumatised\n",
      "Preprocessed: <unk> its not funny im traumatised\n",
      "Actual: üåçNon-disaster\n",
      "Predicted: üåçNon-disaster\n",
      "\n",
      "Input: if you dotish to blight your car go right ahead once its not mine\n",
      "Preprocessed: if you <unk> to blight your car go right ahead once its not mine\n",
      "Actual: üåçNon-disaster\n",
      "Predicted: üåçNon-disaster\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_indexes = np.random.permutation(df_test.shape[0])\n",
    "for sample_index in sample_indexes[:10]:\n",
    "    prediction = model(np.expand_dims(X_test[sample_index], axis=0))[0]\n",
    "    \n",
    "    print('Input:', df_test.iloc[sample_index]['text'])\n",
    "    print('Preprocessed:', ' '.join(tokenizer.index_word[index] for index in np.trim_zeros(X_test[sample_index])))\n",
    "    print('Actual:', 'üåãDisaster' if y_test[sample_index] == 1 else 'üåçNon-disaster')\n",
    "    print('Predicted:', 'üåãDisaster' if prediction[0] >= 0.5 else 'üåçNon-disaster')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
