{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEP532 - 인공지능 이론과 실제 (2022 Spring)\n",
    "## Deep Learning Practice \n",
    "#### Prof. Ho-Jin Choi\n",
    "#### School of Computing, KAIST\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feedforward Neural Network\n",
    "\n",
    "## Implement simple network using TensorFlow \n",
    "\n",
    "### Computation graph\n",
    "The neural network is based on the **computation graph**.\n",
    "\n",
    "Computation graph is composed of the series of operations between tensors. Each operation defines a node in the computaiton graph. Below figure shows an exmaple of computation graph.\n",
    "\n",
    "<img src=\"https://github.com/keai-kaist/SEP532/blob/master/Week1/imgs/computation_graph_ex.png?raw=true\" align=\"center\" width=\"500\" />\n",
    "\n",
    "\n",
    "This graph is a forward function that takes `p`, `q`, and `s` as input variables and computes the output variable `t`. \n",
    "```\n",
    "r = p + q\n",
    "t = r * s = (p + q) * s\n",
    "```\n",
    "  \n",
    "If we assign 3, 5, 2 to `p`, `q`, and `s`, respectively, then we can get `t` that is equal to 16\n",
    "```\n",
    "p = 3  \n",
    "q = 5  \n",
    "s = 2  \n",
    "r = p + q = 8  \n",
    "t = r * s = (p + q) * s = 8 * 2 = 16\n",
    "```\n",
    "\n",
    "This simple process can be easily described using **tensorflow**, as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "p = tf.constant(3)\n",
    "q = tf.constant(5)\n",
    "s = tf.constant(2)\n",
    "r = tf.add(p, q)\n",
    "t = tf.multiply(r, s) \n",
    "\n",
    "print('r :', r)\n",
    "print('t :', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple network \n",
    "\n",
    "Below figure shows very simple nerual network based on computation graph. \n",
    "\n",
    "<img src=\"https://i.imgur.com/NxfQgpy.png\" width=\"600\">\n",
    "\n",
    "In this network, the `x` is a input data, `W` and `b` are weights. To obtain the output, the network conducts perceptron with `x`, `W`, and `b` through the activatin fcuctnion. Using the TensorFlow, we can implement the perceptron process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a variable for weights\n",
    "\n",
    "For the weights, `W` and `b`, we should create a tensor variable with initial values. To do this, we can use `tf.Variable`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "my_variable = tf.Variable(my_tensor)\n",
    "\n",
    "# Variables can be all kinds of types, just like tensors\n",
    "bool_variable = tf.Variable([False, False, False, True])\n",
    "complex_variable = tf.Variable([5 + 4j, 6 + 1j])\n",
    "\n",
    "print(\"Shape: \", my_variable.shape)\n",
    "print(\"DType: \", my_variable.dtype)\n",
    "print(\"As NumPy: \", my_variable.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_in: number of inputs \n",
    "# n_out: number of outputs \n",
    "# suppose that n_in is (1x2), n_out is (1x3)\n",
    "def simple_dense_layer(x, n_in, n_out): \n",
    "    W = tf.Variable(tf.random.uniform((n_in, n_out))) \n",
    "    b = tf.Variable(tf.random.uniform((1, n_out))) \n",
    "    \n",
    "    z = tf.matmul(x, W) + b\n",
    "\n",
    "    out = tf.sigmoid(z)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can define an example input, feed it into `simple_dense_layer` function, and immediately execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an example input (x_input)\n",
    "x_input = tf.constant([[1.0, 2.0]])\n",
    "\n",
    "# TODO: call `our_dense_layer` to get the output of the network\n",
    "print(simple_dense_layer(x_input, n_in=2, n_out=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tnesorflow with Keras\n",
    "\n",
    "Now, instead of explicitly defining a simple function, we'll use the **Keras API**. The Keras is included in the TensorFlow and it provides high-level APIs through the `tf.keras.Sequential` to build more complicated neural network easily as well as low-level APIs to allow the user to custom network structure. \n",
    "\n",
    "First of all, we'll look at the `tf.keras.Sequential`by implementing above simple network . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of inputs and outputs\n",
    "n_input_nodes = 2\n",
    "n_output_nodes = 3\n",
    "\n",
    "# Define a sequential model using Keras API\n",
    "model = tf.keras.Sequential()\n",
    "# Define a dense (fully connected) layer to compute z using Keras API \n",
    "dense_layer = tf.keras.layers.Dense(n_output_nodes, input_shape=(n_input_nodes,), activation='sigmoid')\n",
    "# Add the dense layer to the model\n",
    "model.add(dense_layer)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "model = tf.keras.Sequential(\n",
    "tf.keras.layers.Dense(n_output_nodes, input_shape=(n_input_nodes,), activation='sigmoid')\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FNN-based image classification\n",
    "\n",
    "Now, let's build a Feedforward neural network(FNN) for image classification. The FNN is an one of the basic deep nerual networks. The dataset for classification is a MNIST dataset, well known as handwritten digits. To classify the MNIST image, we build the FNN using the Keras API and train it. Then, test the trained model with test dataset. \n",
    "\n",
    "\n",
    "### MNIST dataset\n",
    "\n",
    "The [MNIST dataset](http://yann.lecun.com/exdb/mnist) is a large database of handwritten digits that is commonly used for training various image processing systems. This dataset consists of 60,000 training images and 10,000 test images. The target classes for this dataset are the digits (0-9). \n",
    "\n",
    "Let's download and load the dataset and display a few random samples from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = np.expand_dims(train_images, axis=-1) / 255\n",
    "train_labels = np.int64(train_labels)\n",
    "\n",
    "test_images = np.expand_dims(test_images, axis=-1) / 255\n",
    "test_labels = np.int64(test_labels)\n",
    "\n",
    "class_names = ['0','1','2','3','4','5','6','7','8','9']\n",
    "\n",
    "print('shape of train_images: ', train_images.shape)\n",
    "print('shape of test_images: ', test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image in the MNIST is made up of 28x28 grayscale of handwritten digits. Let's visualize what some of these images and their corresponding training labels look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "random_indicies = np.random.choice(60000, 36)\n",
    "\n",
    "for index in range(36):\n",
    "    plt.subplot(6, 6, index + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    image_index = random_indicies[index]\n",
    "    plt.imshow(np.squeeze(train_images[image_index]), cmap=plt.cm.binary)\n",
    "    plt.xlabel(train_labels[image_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build classification model \n",
    "\n",
    "To build the FNN for MNIST classification, we use the Keras APIs such as `tf.keras.Sequential` and `tf.keras.Layers`. The structure of the classification model is as follows:\n",
    "\n",
    "<img src=\"https://github.com/keai-kaist/SEP532/blob/master/Week1/imgs/fnn_mnist.png?raw=true\" align=\"center\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a sequential model\n",
    "model = tf.keras.Sequential([\n",
    "    # Add a flatten layer\n",
    "    tf.keras.layers.Flatten(input_shape=train_images.shape[1:]),\n",
    "    \n",
    "    # Add the first dense layer with 128 nodes applying ReLU activation function\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    \n",
    "    # Add the last dense layer with 10 (the number of digits) nodes applying Softmax activation function\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/keai-kaist/SEP532/blob/master/Week1/imgs/flatten.png?raw=true\" align=\"center\" width=\"600\"/>\n",
    "\n",
    "**Flaaten layer** transforms the format of the images from a 2d-array (28 x 28 pixels), to a 1d-array of 784(28 * 28). This layer is for only reformatting the shape of the data so that the model can use it, therefore, it has no learned parameters. \n",
    "\n",
    "after the flatten layer, the network consists of a **sequence of dense layers**. First dense layer is a hidden layer with non-linear function (ReLU activation). Second is as an output layer, the dimension of the layer is same to the number of classes of MNIST. And output layer use the **softmax function** for classification. \n",
    "\n",
    "Softmax function, $ f_j(z) = \\frac{e^{z_j}}{\\sum_{K} e^{z_k}}$, takes a vector of arbitrary real-valued scores and squashes it to **a vector of values between zero and one** that sum to one. This vector represents a probability distribution over predicted output classes given the input value.\n",
    "\n",
    "\n",
    "### Complie the model \n",
    "\n",
    "In this step, we define loss fuction and optimizer for training the model. In the Keras API, we simply achieve that by using the `tf.keras.Model.complie` function. The arguments of the compile function is as follows:\n",
    "\n",
    "- *Loss function*: This defines how we measure how accurate the model is. During training, we want to minimize this function, which will \"steer\" the model in the right direction.\n",
    "- *Optimizer*: This defines how the model is updated based on the data it sees and its loss function.\n",
    "- *Metrics*: Here we can define metrics used to monitor the training and testing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer: adam optimizer\n",
    "# Loss: sparse_categorical_crossentropy \n",
    "# Metrics: accuracy\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model \n",
    "\n",
    "Now, we're ready to train the model. To train the model, we feed the training data, `(train_images, train_labels)`, to the model in units of `batch`. In the case of the complex computations involved in the training step such as forward propagation and backward propagation, we easily implement just using the `fit` function provided in Keras API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the batch size and the number of epochs to use during training\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model using (train_images, train_labels). \n",
    "network_history = model.fit(train_images, \n",
    "                            train_labels, \n",
    "                            epochs=EPOCHS,\n",
    "                            batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting network performance trend\n",
    "\n",
    "The return value of the `fit` function is a `tf.keras.callbacks.History` object which contains the entire history of training/validation loss and accuracy, for each epoch. We can therefore plot the behaviour of loss and accuracy during the training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = network_history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(network_history):\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(network_history.history['loss'])\n",
    "    plt.legend(['Training'])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.plot(network_history.history['accuracy'])\n",
    "    plt.legend(['Training', 'Validation'], loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "plot_history(network_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate accuracy on the test dataset\n",
    "\n",
    "Now that we've trained the model, we can ask it to make predictions about a test set that it hasn't seen before. In this example, the `test_images` array comprises our test dataset. To evaluate accuracy, we can check to see if the model's predictions match the labels from the `test_labels` array. \n",
    "\n",
    "Use the `evaluate` function to evaluate the model on the test dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using (test_images, test_labels)\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print('Test accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make prediction\n",
    "\n",
    "With the model trained, we can use it to make predictions about some images thought the `prediction` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the model has predicted the label for each image in the testing set. Let's take a look at the first prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions[0])\n",
    "plt.imshow(np.squeeze(test_images[0]), cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Predicted digit for test image[0]: {}'.format(np.argmax(predictions[0])))\n",
    "\n",
    "print('Ground truth of test image[0]: {}'.format(test_labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.imshow(np.squeeze(img), cmap=plt.cm.binary)\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    predictions_array, true_label = predictions_array, true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks(range(10))\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 8 \n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_image(i, predictions[i], test_labels, test_images)\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_value_array(i, predictions[i], test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first X test images, their predicted labels, and the true labels.\n",
    "# Color correct predictions in blue and incorrect predictions in red.\n",
    "num_rows = 5\n",
    "num_cols = 3\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "    plot_image(i, predictions[i], test_labels, test_images)\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "    plot_value_array(i, predictions[i], test_labels)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
